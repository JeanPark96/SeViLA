{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4204c7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from moviepy.editor import *\n",
    "from decord import VideoReader\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb4ec4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampling_rate= 1\n",
    "def verify_frame_len(video_path, frame_idx):\n",
    "    if video_path.endswith(\".mp4\"):\n",
    "        video = VideoFileClip(video_path)\n",
    "    else:\n",
    "        video = VideoFileClip(video_path + \".mp4\")\n",
    "    n_frames = video.reader.nframes\n",
    "    if n_frames // (downsampling_rate * video.fps) != max(frame_idx) + 1:\n",
    "        print(\"ERROR\", video.fps, n_frames, max(frame_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e807f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_consecutive_timestamps(timestamps):\n",
    "    \"\"\"\n",
    "    Function to find consecutive timestamps in a list and record the start and end time.\n",
    "    \"\"\"\n",
    "    if not timestamps:\n",
    "        return []\n",
    "\n",
    "    # Initialize the first start time and the result list\n",
    "    start = timestamps[0]\n",
    "    result = []\n",
    "    \n",
    "    for i in range(1, len(timestamps)):\n",
    "        # Check if the current timestamp is not consecutive\n",
    "        if timestamps[i] != timestamps[i-1] + 1:\n",
    "            # Record the previous consecutive sequence\n",
    "            result.append([start, timestamps[i-1]])\n",
    "            # Update the start for the new sequence\n",
    "            start = timestamps[i]\n",
    "\n",
    "    # Add the last sequence\n",
    "    result.append([start, timestamps[-1]])\n",
    "\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "# timestamps = [0, 1, 2, 3, 4, 8, 10, 11, 12]\n",
    "# find_consecutive_timestamps(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4c5c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(ground_truth, predictions):\n",
    "    \"\"\"\n",
    "    Calculate the Intersection over Union (IoU) for video moment retrieval.\n",
    "    \n",
    "    :param ground_truth: A tuple representing the ground truth interval (start, end).\n",
    "    :param predictions: A list of tuples representing predicted intervals [(start1, end1), (start2, end2), ...].\n",
    "    :return: IoU score.\n",
    "    \"\"\"\n",
    "    GT_start, GT_end = ground_truth\n",
    "    total_intersection = 0\n",
    "    total_union = 0\n",
    "\n",
    "    for (P_start, P_end) in predictions:\n",
    "        # Calculate intersection\n",
    "        intersection = max(0, min(GT_end, P_end) - max(GT_start, P_start))\n",
    "        total_intersection += intersection\n",
    "\n",
    "        # Calculate union for this predicted interval\n",
    "        union = (P_end - P_start)  - intersection\n",
    "        total_union += union\n",
    "    total_union += (GT_end - GT_start)\n",
    "    # Avoid division by zero\n",
    "    if total_union == 0:\n",
    "        return 0\n",
    "\n",
    "    # Calculate IoU\n",
    "    iou = total_intersection / total_union\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09845339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(content, save_path):\n",
    "    with open(save_path, 'w') as f:\n",
    "        f.write(json.dumps(content))\n",
    "def load_jsonl(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        return [json.loads(l.strip(\"\\n\")) for l in f.readlines()]\n",
    "        # return json.loads(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93c7723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set folder path\n",
    "root_path = \"/home/hlpark/REDUCE/REDUCE_benchmarks/SeViLA/sevila_data/tvqa\"\n",
    "video_root = \"/home/hlpark/shared/TVQA/video/video_files\"\n",
    "\n",
    "val_path = \"/home/hlpark/REDUCE/REDUCE_benchmarks/SeViLA/sevila_data/tvqa_evaluation_json/val_gt.json\"\n",
    "original = \"/home/hlpark/REDUCE/REDUCE_benchmarks/SeViLA/sevila_tvqa_hirest_prediction_gt/original\"\n",
    "finetuned_on_visual_nonmed = \"/home/hlpark/REDUCE/REDUCE_benchmarks/SeViLA/sevila_tvqa_hirest_prediction_gt/finetuned_on_visual_nonmed\"\n",
    "finetuned_on_visual_med = \"/home/hlpark/REDUCE/REDUCE_benchmarks/SeViLA/sevila_tvqa_hirest_prediction_gt/finetuned_on_visual_med\"\n",
    "finetuned_on_full_without_audio = \"/home/hlpark/REDUCE/REDUCE_benchmarks/SeViLA/sevila_tvqa_hirest_prediction_gt/finetuned_on_full_without_audio\"\n",
    "\n",
    "original = \"/home/hlpark/REDUCE/REDUCE_benchmarks/SeViLA/sevila_tvqa_hirest_prediction_gt_fulldata/original\"\n",
    "finetuned_on_visual_nonmed = \"/home/hlpark/REDUCE/REDUCE_benchmarks/SeViLA/sevila_tvqa_hirest_prediction_gt_fulldata/finetuned_on_visual_nonmed\"\n",
    "finetuned_on_visual_med = \"/home/hlpark/REDUCE/REDUCE_benchmarks/SeViLA/sevila_tvqa_hirest_prediction_gt_fulldata/finetuned_on_visual_med\"\n",
    "finetuned_on_full_without_audio = \"/home/hlpark/REDUCE/REDUCE_benchmarks/SeViLA/sevila_tvqa_hirest_prediction_gt_fulldata/finetuned_on_full_without_audio\"\n",
    "\n",
    "\n",
    "vid_json_folder = \"/home/hlpark/REDUCE/REDUCE_benchmarks/HiREST/data/splits/tvqa\"\n",
    "clip_pred_med = load_jsonl(f'{vid_json_folder}/five_labeled_pred_med_from_gt_vid_dict.json')\n",
    "gt_validation = load_jsonl(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e569c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Number of processed queries for original:  15238\n",
      "\n",
      "accuracy\n",
      "0.23408583803648772\n",
      "0.2376897445390596\n",
      "0.23330940416367552\n",
      "\n",
      "F1\n",
      "0.1603892998991908\n",
      "0.15488820728101885\n",
      "0.16158369840786085\n",
      "file not found  [Errno 2] No such file or directory: '/home/hlpark/REDUCE/REDUCE_benchmarks/SeViLA/sevila_tvqa_hirest_prediction_gt_fulldata/finetuned_on_visual_nonmed/result/val_epochbest.json'\n",
      "\n",
      "\n",
      "Number of processed queries for finetuned_on_visual_nonmed:  0\n",
      "\n",
      "accuracy\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "F1\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "\n",
      "\n",
      "Number of processed queries for finetuned_on_visual_med:  15238\n",
      "\n",
      "accuracy\n",
      "0.21603885024281402\n",
      "0.22769344687152906\n",
      "0.21352795724655024\n",
      "\n",
      "F1\n",
      "0.10961212854005087\n",
      "0.11712718091139554\n",
      "0.1080535911266263\n",
      "file not found  [Errno 2] No such file or directory: '/home/hlpark/REDUCE/REDUCE_benchmarks/SeViLA/sevila_tvqa_hirest_prediction_gt_fulldata/finetuned_on_full_without_audio/result/val_epochbest.json'\n",
      "\n",
      "\n",
      "Number of processed queries for finetuned_on_full_without_audio:  0\n",
      "\n",
      "accuracy\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "F1\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "# TVQA 32 frames from ground truth\n",
    "tvqa_val_json = [original, finetuned_on_visual_nonmed, finetuned_on_visual_med, finetuned_on_full_without_audio]\n",
    "tvqa_pred_type = [\"original\", \"finetuned_on_visual_nonmed\", \"finetuned_on_visual_med\", \"finetuned_on_full_without_audio\"]\n",
    "# tvqa_pred_type = [x + \"_pt3\" for x in tvqa_pred_type]\n",
    "# tvqa_val_json = [x + \"_pt3\" for x in tvqa_val_json]\n",
    "tvqa_list = []\n",
    "\n",
    "split = \"val\"\n",
    "\n",
    "\n",
    "fileerr = 0\n",
    "for idx, val_json in enumerate(tvqa_val_json):\n",
    "    target_list, pred_list = [], []\n",
    "    med_target, med_pred = [], []\n",
    "    nonmed_target, nonmed_pred = [], []\n",
    "    wrong_queries_32, correct_queries_32 = [], []\n",
    "    video_list = []\n",
    "    \n",
    "    try:\n",
    "        tvqa = load_jsonl(os.path.join(tvqa_val_json[idx], \"result\", \"val_epochbest.json\"))\n",
    "\n",
    "        max_frame_num = 0\n",
    "\n",
    "        #remove duplicate queries in tvqa[0]\n",
    "        seen_qid = []\n",
    "        for qa in tvqa[0][:]:\n",
    "            if qa['qid'] not in seen_qid:\n",
    "                seen_qid.append(qa['qid'])\n",
    "            else:\n",
    "                tvqa[0].remove(qa)\n",
    "                #print(\"remove duplicate \", qa['qid'])\n",
    "\n",
    "        for i, qa in enumerate(tvqa[0]):\n",
    "            max_frame_num = max(qa['frame_idx'])\n",
    "            \n",
    "            try:\n",
    "                # for idx, value in enumerate(gt_validation[0]):\n",
    "                #     print(value)\n",
    "                qa['video'] = [value['video'] for idx, value in enumerate(gt_validation[0]) if value['qid'] == qa['qid']][0]\n",
    "                qa['question'] = [value['question'] for idx, value in enumerate(gt_validation[0])  if value['qid'] == qa['qid']][0]\n",
    "                #print(qa['video'], qa['question'])\n",
    "            \n",
    "                \n",
    "                pred_list.append(qa['prediction'])\n",
    "                target_list.append(qa['target'])\n",
    "                ismed = False\n",
    "                if qa['prediction'] == qa['target']:\n",
    "                    correct_queries_32.append(qa)\n",
    "                else:\n",
    "                    wrong_queries_32.append(qa)\n",
    "                for qc in clip_pred_med[0][qa['video']]:\n",
    "                    #print(qc)\n",
    "                    if qa['question'] in qc and qc[qa['question']] == \"med\":\n",
    "                        ismed = True\n",
    "                if ismed:\n",
    "                #if clip_pred_med[0][qa['vid_name'] + \".mp4\"] == \"med\":\n",
    "                #if \"house\" in dic['vid_name'] or \"grey\" in dic['vid_name']:\n",
    "                    med_pred.append(qa['prediction'])\n",
    "                    med_target.append(qa['target'])\n",
    "                else:\n",
    "                    nonmed_pred.append(qa['prediction'])\n",
    "                    nonmed_target.append(qa['target'])\n",
    "            except ValueError as e:\n",
    "                #print(dic['time_span_len'])\n",
    "                print(\"ValueError \", qa['qid'], qa['frame_idx'], e)\n",
    "                qa['pred'] = [0, 0]\n",
    "                qa['iou'] = 0\n",
    "                #uncomment this only when you want to check frame length for verification purpose\n",
    "                #verify_frame_len(tvqa_video,  qa['frame_idx'])\n",
    "                \n",
    "                \n",
    "                \n",
    "    except FileNotFoundError as e: \n",
    "        print(\"file not found \", e)\n",
    "        fileerr +=1\n",
    "    print(f\"\\n\\nNumber of processed queries for {tvqa_pred_type[idx]}: \", len(target_list))\n",
    "    print(\"\\naccuracy\")\n",
    "    print(f1_score(target_list, pred_list, average=\"micro\"))\n",
    "    print(f1_score(med_target, med_pred, average=\"micro\"))\n",
    "    print(f1_score(nonmed_target, nonmed_pred, average=\"micro\"))\n",
    "    print(\"\\nF1\")\n",
    "    print(f1_score(target_list, pred_list, average=\"weighted\"))\n",
    "    print(f1_score(med_target, med_pred, average=\"weighted\"))\n",
    "    print(f1_score(nonmed_target, nonmed_pred, average=\"weighted\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b84a42b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
